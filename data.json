# -*- coding: utf-8 -*-
"""
AI Hunter - å…¨çƒå¢å¼ºç‰ˆ
æ–°å¢ï¼š
  - æŠ“å– There's An AI For That (via official API)
  - æŠ“å– FutureTools.io
  - æŠ“å– faxianai.com
  - æ•°æ®æ¸…æ´— + æ™ºèƒ½åˆ†ç±» + å»é‡
"""

import json
import requests
from bs4 import BeautifulSoup
import time
import random

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
}

def clean_text(text):
    """ç§»é™¤æ§åˆ¶å­—ç¬¦ï¼Œä¿ç•™åˆæ³•ç©ºç™½"""
    if not text:
        return ""
    return ''.join(c for c in str(text) if ord(c) >= 32 or c in '\n\t\r')

# ========================
# åˆ†ç±»å…³é”®è¯ï¼ˆä¸­è‹±æ–‡ï¼‰
# ========================

COST_KEYWORDS = [
    'å®¢æœ', 'äººåŠ›', 'èŠ‚çœ', 'é™æœ¬', 'æ›¿ä»£', 'è‡ªåŠ¨åŒ–', 'å¤–åŒ…', 'å‡å°‘', 'ä½æˆæœ¬',
    'å…è´¹', 'å¼€æº', 'è®¡è´¹', 'é¢„ç®—', 'è´¢åŠ¡', 'æŠ¥é”€', 'åˆåŒ', 'æ³•åŠ¡', 'æ‹›è˜',
    'cost', 'save money', 'reduce cost', 'replace', 'automate', 'free', 'open source',
    'budget', 'cheaper', 'cut expenses', 'customer service', 'outsourcing'
]

EFFICIENCY_KEYWORDS = [
    'æ•ˆç‡', 'æå‡', 'åŠ é€Ÿ', 'å¿«é€Ÿ', 'ä¸€é”®', 'è‡ªåŠ¨ç”Ÿæˆ', 'æ™ºèƒ½', 'ç§’å‡º', 'æ‰¹é‡',
    'è®¾è®¡', 'å‰ªè¾‘', 'å†™ä½œ', 'PPT', 'å‘¨æŠ¥', 'ä¼šè®®', 'ç¿»è¯‘', 'æŠ å›¾', 'æ’ç‰ˆ', 'ç»˜å›¾',
    'efficiency', 'boost', 'speed up', 'automate', 'generate', 'design', 'write',
    'edit', 'translate', 'create', 'productivity', 'workflow', 'fast', 'instant',
    'batch', 'summarize', 'analyze'
]

def classify_tool(desc, title):
    text = (clean_text(title) + " " + clean_text(desc)).lower()
    cost_score = sum(1 for kw in COST_KEYWORDS if kw in text)
    eff_score = sum(1 for kw in EFFICIENCY_KEYWORDS if kw in text)
    return "cost" if cost_score > eff_score else "efficiency"

def deduplicate(tools):
    seen = set()
    unique = []
    for t in tools:
        key = t['title'].strip().lower()
        if key and key not in seen:
            seen.add(key)
            unique.append(t)
    return unique[:20]  # é™åˆ¶æ€»æ•°

# ========================
# æŠ“å– Thereâ€™s An AI For Thatï¼ˆæ ¸å¿ƒï¼ï¼‰
# ========================

def fetch_theresanaiforthat(max_items=30):
    tools = []
    try:
        print("ğŸŒ è°ƒç”¨ There's An AI For That API...")
        res = requests.get(
            "https://theresanaiforthat.com/api/all/",
            headers={"User-Agent": "AI-Hunter-Bot"},
            timeout=20
        )
        data = res.json()
        for item in data[:max_items]:
            title = clean_text(item.get('name', ''))
            desc = clean_text(item.get('description_short', ''))
            url = item.get('url', '#')
            if title and url != '#':
                tools.append({
                    "title": title,
                    "desc": desc,
                    "source": url
                })
        print(f"âœ… è·å– {len(tools)} ä¸ªå›½é™…å·¥å…·")
    except Exception as e:
        print(f"âš ï¸ There's An AI For That æŠ“å–å¤±è´¥: {e}")
    return tools

# ========================
# æŠ“å– FutureTools.io
# ========================

def fetch_futuretools(max_items=10):
    tools = []
    try:
        res = requests.get("https://www.futuretools.io", headers=HEADERS, timeout=15)
        soup = BeautifulSoup(res.text, 'html.parser')
        cards = soup.select('div[role="article"]')[:max_items]
        for card in cards:
            title_elem = card.select_one('h2 a')
            desc_elem = card.select_one('p')
            if not title_elem: continue
            title = clean_text(title_elem.get_text(strip=True))
            desc = clean_text(desc_elem.get_text(strip=True)) if desc_elem else ""
            source = title_elem['href'] if title_elem.has_attr('href') else "#"
            if title:
                tools.append({"title": title, "desc": desc, "source": source})
    except Exception as e:
        print(f"âš ï¸ FutureTools æŠ“å–å¤±è´¥: {e}")
    return tools

# ========================
# æŠ“å– å›½å†…ï¼šå‘ç°AI
# ========================

def fetch_faxianai(max_items=8):
    tools = []
    try:
        res = requests.get("https://faxianai.com", headers=HEADERS, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        cards = soup.select('a[href^="/tool/"]')[:max_items]
        for card in cards:
            title = clean_text(card.select_one('h3').get_text(strip=True)) if card.select_one('h3') else ""
            desc = clean_text(card.select_one('p').get_text(strip=True)) if card.select_one('p') else ""
            tag = clean_text(card.select_one('span.bg-blue-100').get_text(strip=True)) if card.select_one('span.bg-blue-100') else ""
            source = "https://faxianai.com" + card['href']
            if title:
                tools.append({"title": title, "desc": f"{desc} {tag}".strip(), "source": source})
    except Exception as e:
        print(f"âš ï¸ å‘ç°AIæŠ“å–å¤±è´¥: {e}")
    return tools

# ========================
# æ‰‹åŠ¨å…œåº•æ•°æ®
# ========================

def get_manual_tools():
    return {
        "cost": [
            {"title": "Doubao (è±†åŒ…)", "desc": "Free AI assistant for customer service", "source": "https://www.doubao.com"},
            {"title": "WPS AI", "desc": "Automate office tasks, reduce software costs", "source": "https://www.wps.cn/ai"}
        ],
        "efficiency": [
            {"title": "Meitu (ç¾å›¾ç§€ç§€)", "desc": "AI photo editing in seconds", "source": "https://xiuxiu.meitu.com"},
            {"title": "Qwen (é€šä¹‰åƒé—®)", "desc": "Generate reports, emails, and summaries instantly", "source": "https://qwen.ai"},
            {"title": "Canva Magic Studio", "desc": "Create designs with text prompts", "source": "https://www.canva.com/magic-studio/"},
            {"title": "Notion AI", "desc": "Write, summarize, and organize your work", "source": "https://www.notion.so/product/ai"}
        ]
    }

# ========================
# è¶‹åŠ¿æ–°é—»
# ========================

def get_trend_news(max_items=3):
    try:
        res = requests.get("https://36kr.com/newsflashes", headers=HEADERS, timeout=10)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        items = []
        for item in soup.select('div.newsflash-item')[:max_items]:
            title_elem = item.select_one('a.article-title')
            if not title_elem: continue
            title = clean_text(title_elem.get_text(strip=True))
            link = "https://36kr.com" + title_elem['href'] if title_elem.has_attr('href') else "#"
            if any(kw in title for kw in ['AI', 'äººå·¥æ™ºèƒ½', 'å¤§æ¨¡å‹', 'AIGC']):
                items.append({"title": title, "desc": "Source: 36Kr", "source": link})
        return items or [{"title": "Global AI adoption accelerates", "desc": "Enterprise demand surges", "source": "https://36kr.com"}]
    except:
        return [{"title": "Trends loading...", "desc": "Check back later", "source": "#"}]

# ========================
# ä¸»ç¨‹åº
# ========================

def main():
    print("ğŸš€ å¼€å§‹æŠ“å–å…¨çƒ AI å·¥å…·...")

    all_tools = []

    # æŠ“å–ä¸‰å¤§æ¥æº
    all_tools.extend(fetch_theresanaiforthat(max_items=40))
    all_tools.extend(fetch_futuretools(max_items=10))
    all_tools.extend(fetch_faxianai(max_items=8))

    # æ¸…æ´— & å»é‡
    all_tools = deduplicate(all_tools)

    # åˆ†ç±»
    cost_list = []
    efficiency_list = []
    for tool in all_tools:
        category = classify_tool(tool['desc'], tool['title'])
        if category == "cost":
            cost_list.append(tool)
        else:
            efficiency_list.append(tool)

    # å…œåº•
    manual = get_manual_tools()
    if len(cost_list) < 2:
        cost_list = manual["cost"]
    if len(efficiency_list) < 3:
        efficiency_list = manual["efficiency"]

    trend = get_trend_news()

    # ä¿å­˜ä¸ºåˆæ³• JSON
    data = {
        "cost": cost_list,
        "efficiency": efficiency_list,
        "trend": trend
    }

    with open('data.json', 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… data.json å·²ç”Ÿæˆï¼")
    print(f"   - æˆæœ¬æ€æ‰‹: {len(cost_list)} ä¸ª")
    print(f"   - æ•ˆç‡å€å¢: {len(efficiency_list)} ä¸ª")
    print(f"   - è¶‹åŠ¿é›·è¾¾: {len(trend)} æ¡")

if __name__ == "__main__":
    main()