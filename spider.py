import os
import json
import ftplib
from datetime import datetime

# ==========================================
# 1. æ¨¡æ‹ŸæŠ“å–é€»è¾‘ (å­—æ®µåå·²ä¿®æ­£ï¼Œç¡®ä¿ä¸ index.html åŒ¹é…)
# ==========================================
import requests
from bs4 import BeautifulSoup

def fetch_industry_leads():
    print("ğŸš€ æ­£åœ¨å¯åŠ¨çœŸå®çˆ¬è™«å¼•æ“ï¼Œæ‰«æè¡Œä¸šå…¬å¼€æƒ…æŠ¥...")
    real_leads = []
    
    # ç¤ºä¾‹ï¼šæŠ“å–æŸä¸ªè¡Œä¸šå…¬å‘Šé¡µï¼ˆè¿™é‡Œå¡«å…¥ä½ å…³æ³¨çš„æ‹›æ ‡ç½‘æˆ–æ–°é—»åœ°å€ï¼‰
    target_url = "https://www.example-bidding.com/search?q=å°ç„Šæœº" 
    
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(target_url, timeout=10, headers=headers)
        response.encoding = 'utf-8'
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # å‡è®¾ç½‘é¡µä¸Šçš„æ¯ä¸€æ¡å…¬å‘Šéƒ½åœ¨ <div class="news-item"> é‡Œ
            # è¿™éƒ¨åˆ†éœ€è¦æ ¹æ®ä½ ç›®æ ‡ç½‘ç«™çš„ HTML ç»“æ„å…·ä½“è°ƒæ•´
            items = soup.find_all('div', class_='news-item') 
            
            for i, item in enumerate(items[:5]): # åªå–å‰5æ¡æœ€æ–°çº¿ç´¢
                real_leads.append({
                    "id": int(datetime.now().timestamp()) + i,
                    "company": item.find('span', class_='company').text.strip(),
                    "location": "æƒ…æŠ¥è§£æä¸­",
                    "category": "domestic",
                    "tag": "å®æ—¶æ‹›æ ‡",
                    "reason": item.find('a').text.strip(), # æŠ“å–æ ‡é¢˜ä½œä¸ºç†ç”±
                    "website": target_url,
                    "phone": "è§åŸå…¬å‘Š"
                })
        
        if not real_leads:
            print("âš ï¸ æœªèƒ½ä»ç›®æ ‡ç½‘é¡µè§£æåˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥é€‰æ‹©å™¨ç»“æ„ã€‚")
            
    except Exception as e:
        print(f"âŒ çœŸå®æŠ“å–å¤±è´¥: {e}")
        
    return real_leads if real_leads else fetch_mock_data() # å¦‚æœæŠ“ä¸åˆ°å°±å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®

# ==========================================
# 2. ç”Ÿæˆ JSON æ•°æ®æ–‡ä»¶ (ä¿æŒä¸å˜)
# ==========================================
def save_to_json(data):
    file_path = 'data.json'
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ… æ•°æ®å·²æˆåŠŸå†™å…¥æœ¬åœ° {file_path}")
    except Exception as e:
        print(f"âŒ å†™å…¥ JSON å¤±è´¥: {e}")

# ==========================================
# 3. ä¼ å›é˜¿é‡Œäº‘è™šæ‹Ÿç©ºé—´ (ä¿æŒä¸å˜)
# ==========================================
def upload_to_server():
    FTP_SERVER = "qxu1590320302.my3w.com"
    FTP_USER = "qxu1590320302"
    FTP_PASS = "123456ab"

    try:
        print(f"æ­£åœ¨è¿æ¥ FTP: {FTP_SERVER} ...")
        session = ftplib.FTP()
        session.connect(FTP_SERVER, 21, timeout=30)
        session.login(FTP_USER, FTP_PASS)
        session.set_pasv(True)
        
        try:
            session.cwd('/htdocs')
        except:
            print("å·²ç»åœ¨æ ¹ç›®å½•æˆ– htdocs æ— æ³•è®¿é—®")
        
        # ç¡®ä¿åŒæ­¥æœ€æ–°çš„ä¸‰ä¸ªæ ¸å¿ƒæ–‡ä»¶
        files_to_send = ['index.html', 'spider.html', 'data.json']
        
        for file_name in files_to_send:
            if os.path.exists(file_name):
                with open(file_name, 'rb') as f:
                    session.storbinary(f'STOR {file_name}', f)
                    print(f"ğŸš€ å·²æˆåŠŸåŒæ­¥åˆ°ç©ºé—´: {file_name}")
            else:
                print(f"âš ï¸ è·³è¿‡: æœ¬åœ°æœªæ‰¾åˆ° {file_name}")

        session.quit()
        print(f"âœ¨ å®æ—¶åŒæ­¥å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ ä¼ è¾“å¤±è´¥: {e}")

# ==========================================
# 4. ç»Ÿä¸€æ‰§è¡Œå…¥å£
# ==========================================
if __name__ == "__main__":
    leads = fetch_industry_leads()
    save_to_json(leads)
    upload_to_server()

