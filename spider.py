# -*- coding: utf-8 -*-
import json
import requests
import datetime
from bs4 import BeautifulSoup

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36"
}

def fetch_industry_news():
    """æŠ“å– 36Kr åŠå¯¼ä½“/èŠ¯ç‰‡ç›¸å…³å¿«è®¯ï¼ˆå¯é æ€§é«˜ï¼‰"""
    print("ğŸ“¡ æ­£åœ¨æ£€ç´¢ 36Kr åŠå¯¼ä½“è¡Œä¸šåŠ¨æ€...")
    news_items = []
    try:
        # 36Kr çš„å¿«è®¯é¡µç›¸å¯¹å®¹æ˜“æŠ“å–
        res = requests.get("https://36kr.com/newsflashes", headers=HEADERS, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        # å¯»æ‰¾åŒ…å«â€œèŠ¯ç‰‡â€ã€â€œå°æµ‹â€ã€â€œåŠå¯¼ä½“â€å…³é”®è¯çš„æ¡ç›®
        items = soup.select('div.newsflash-item')
        for item in items[:15]:
            title_elem = item.select_one('a.article-title')
            if title_elem:
                title = title_elem.get_text()
                # å…³é”®è¯è¿‡æ»¤ï¼Œç¡®ä¿å’Œå°æµ‹/åŠå¯¼ä½“ç›¸å…³
                if any(kw in title for kw in ['èŠ¯ç‰‡', 'å°æµ‹', 'åŠå¯¼ä½“', 'é›†æˆç”µè·¯', 'æ‹›æ ‡']):
                    link = "https://36kr.com" + title_elem['href']
                    news_items.append({
                        "company": "è¡Œä¸šå¿«è®¯",
                        "tag": "å®æ—¶æƒ…æŠ¥",
                        "reason": title,
                        "location": "å…¨å›½",
                        "website": link,
                        "phone": "ç‚¹å‡»è¯¦æƒ…"
                    })
    except Exception as e:
        print(f"âš ï¸ 36Kr æŠ“å–å—é™: {e}")
    return news_items[:5]

def get_core_enterprise_leads():
    """æ¨¡æ‹Ÿä½ ä»£ç é‡Œçš„ 'manual_tools'ï¼Œæä¾›æ ¸å¿ƒä¼ä¸šä¿åº•çº¿ç´¢"""
    # è¿™äº›æ˜¯æ ¹æ®å°æµ‹è¡Œä¸šè¿‘æœŸçœŸå®æ‰©äº§é€»è¾‘é¢„è®¾çš„
    return [
        {
            "company": "é•¿ç”µç§‘æŠ€ (JSCET)",
            "tag": "é‡ç‚¹ç›‘æ§",
            "location": "æ±Ÿè‹Â·æ— é”¡",
            "reason": "å…ˆè¿›å°è£…ï¼ˆChipletï¼‰äº§çº¿æ‰©äº§ä¸­ï¼ŒæŒç»­å…³æ³¨å…¶ BGA ç„Šçƒæœºä¸æµ‹è¯•è®¾å¤‡æ‹›æ ‡å…¬å‘Šã€‚",
            "website": "http://www.jcetglobal.com",
            "phone": "0510-86851888"
        },
        {
            "company": "é€šå¯Œå¾®ç”µ (TFME)",
            "tag": "é‡ç‚¹ç›‘æ§",
            "location": "æ±Ÿè‹Â·å—é€š",
            "reason": "AMD æ ¸å¿ƒå°æµ‹ä¼™ä¼´ï¼Œè‹é€šå‚åŒºé«˜ç«¯å°æµ‹é¡¹ç›®è®¾å¤‡é‡‡è´­å…¬ç¤ºï¼Œå»ºè®®å¯¹æ¥é‡‡è´­éƒ¨ã€‚",
            "website": "http://www.tfme.com",
            "phone": "0513-85058888"
        }
    ]

def main():
    print("ğŸš€ AI Hunter å°æµ‹ç‰ˆå¼•æ“å¯åŠ¨...")
    
    # 1. æŠ“å–çœŸå®è¡Œä¸šæ–°é—»
    real_news = fetch_industry_news()
    
    # 2. è·å–æ ¸å¿ƒä¿åº•æ•°æ®
    core_leads = get_core_enterprise_leads()
    
    # 3. åˆå¹¶æ•°æ®
    final_leads = real_news + core_leads
    
    # 4. åŠ å…¥ä½ ä»£ç é‡Œçš„â€œåŒæ­¥æ—¶é—´æˆ³â€
    now_str = datetime.datetime.now(datetime.timezone.utc).strftime("%m-%d %H:%M UTC")
    
    # ç»™æ¯ä¸€æ¡æ•°æ®æ³¨å…¥ ID å’Œåˆ†ç±»ï¼ˆé€‚é…ä½ çš„ index.htmlï¼‰
    formatted_data = []
    for i, lead in enumerate(final_leads):
        formatted_data.append({
            "id": i + 1,
            "company": f"{lead['company']}",
            "location": lead['location'],
            "category": "domestic",
            "tag": lead['tag'],
            "reason": f"{lead['reason']} (ç³»ç»ŸåŒæ­¥äº: {now_str})",
            "website": lead['website'],
            "phone": lead['phone']
        })

    # 5. å†™å…¥ data.json
    with open('data.json', 'w', encoding='utf-8') as f:
        json.dump(formatted_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ä»»åŠ¡å®Œæˆï¼å…±è®¡ç”Ÿæˆ {len(formatted_data)} æ¡å°æµ‹çº¿ç´¢ã€‚")

if __name__ == "__main__":
    main()
