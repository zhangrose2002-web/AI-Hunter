# -*- coding: utf-8 -*-
"""
AI Hunter - å…¨çƒç‰ˆï¼ˆGitHub Actions ä¼˜åŒ–ç‰ˆï¼‰
æŠ“å–å›½å†…å¤–çƒ­é—¨ AI å·¥å…·ï¼Œå¹¶æ™ºèƒ½åˆ†ç±»åˆ° cost / efficiency
è‡ªåŠ¨å»é‡ã€å…œåº•ã€ç”Ÿæˆæ ‡å‡† data.json
"""

import json
import requests
from bs4 import BeautifulSoup
import sys
import os

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36"
}

def clean_text(text):
    """å®‰å…¨æ¸…ç†æ–‡æœ¬ï¼šç§»é™¤æ§åˆ¶å­—ç¬¦ï¼Œä¿ç•™åˆæ³•ç©ºç™½"""
    if not text:
        return ""
    return ''.join(c for c in str(text) if ord(c) >= 32 or c in '\n\t\r')

# ========================
# åˆ†ç±»å…³é”®è¯ï¼ˆä¸­è‹±æ–‡ï¼‰
# ========================

COST_KEYWORDS = [
    # ä¸­æ–‡
    'å®¢æœ', 'äººåŠ›', 'èŠ‚çœ', 'é™æœ¬', 'æ›¿ä»£', 'è‡ªåŠ¨åŒ–', 'å¤–åŒ…', 'å‡å°‘', 'ä½æˆæœ¬',
    'å…è´¹', 'å¼€æº', 'è®¡è´¹', 'é¢„ç®—', 'è´¢åŠ¡', 'æŠ¥é”€', 'åˆåŒ', 'æ³•åŠ¡', 'æ‹›è˜',
    # è‹±æ–‡
    'cost', 'save money', 'reduce cost', 'replace', 'automate', 'free', 'open source',
    'budget', 'cheaper', 'cut expenses', 'customer service', 'outsourcing'
]

EFFICIENCY_KEYWORDS = [
    # ä¸­æ–‡
    'æ•ˆç‡', 'æå‡', 'åŠ é€Ÿ', 'å¿«é€Ÿ', 'ä¸€é”®', 'è‡ªåŠ¨ç”Ÿæˆ', 'æ™ºèƒ½', 'ç§’å‡º', 'æ‰¹é‡',
    'è®¾è®¡', 'å‰ªè¾‘', 'å†™ä½œ', 'PPT', 'å‘¨æŠ¥', 'ä¼šè®®', 'ç¿»è¯‘', 'æŠ å›¾', 'æ’ç‰ˆ', 'ç»˜å›¾',
    # è‹±æ–‡
    'efficiency', 'boost', 'speed up', 'automate', 'generate', 'design', 'write',
    'edit', 'translate', 'create', 'productivity', 'workflow', 'fast', 'instant',
    'batch', 'summarize', 'analyze'
]

def classify_tool(desc, title):
    text = (clean_text(title) + " " + clean_text(desc)).lower()
    cost_score = sum(1 for kw in COST_KEYWORDS if kw in text)
    eff_score = sum(1 for kw in EFFICIENCY_KEYWORDS if kw in text)
    return "cost" if cost_score > eff_score else "efficiency"

def deduplicate(tools):
    seen = set()
    unique = []
    for t in tools:
        key = clean_text(t['title']).strip().lower()
        if key and key not in seen:
            seen.add(key)
            unique.append(t)
    return unique

# ========================
# æŠ“å–å›½å†…ï¼šå‘ç°AI
# ========================

def fetch_faxianai(max_items=8):
    tools = []
    try:
        res = requests.get("https://faxianai.com", headers=HEADERS, timeout=10)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        cards = soup.select('a[href^="/tool/"]')[:max_items]
        for card in cards:
            title_elem = card.select_one('h3')
            desc_elem = card.select_one('p')
            tag_elem = card.select_one('span.bg-blue-100')
            title = clean_text(title_elem.get_text(strip=True)) if title_elem else ""
            desc = clean_text(desc_elem.get_text(strip=True)) if desc_elem else ""
            tag = clean_text(tag_elem.get_text(strip=True)) if tag_elem else ""
            source = "https://faxianai.com" + card['href']
            if title:
                tools.append({"title": title, "desc": f"{desc} {tag}".strip(), "source": source})
    except Exception as e:
        print(f"âš ï¸ å‘ç°AIæŠ“å–å¤±è´¥: {e}")
    return tools

# ========================
# æŠ“å–å›½å¤–ï¼šFutureTools.io
# ========================

def fetch_futuretools(max_items=10):
    tools = []
    try:
        res = requests.get("https://www.futuretools.io", headers=HEADERS, timeout=15)
        soup = BeautifulSoup(res.text, 'html.parser')
        cards = soup.select('div[role="article"]')[:max_items]
        for card in cards:
            title_elem = card.select_one('h2 a')
            desc_elem = card.select_one('p')
            if not title_elem:
                continue
            title = clean_text(title_elem.get_text(strip=True))
            desc = clean_text(desc_elem.get_text(strip=True)) if desc_elem else ""
            source = title_elem['href'] if title_elem.has_attr('href') else "#"
            if title:
                tools.append({"title": title, "desc": desc, "source": source})
    except Exception as e:
        print(f"âš ï¸ FutureToolsæŠ“å–å¤±è´¥: {e}")
    return tools

# ========================
# æ‰‹åŠ¨å…œåº•æ•°æ®
# ========================

def get_manual_tools():
    return {
        "cost": [
            {"title": "Doubao (è±†åŒ…)", "desc": "å…è´¹ AI åŠ©æ‰‹ï¼Œé€‚ç”¨äºå®¢æœä¸æ—¥å¸¸é—®ç­”", "source": "https://www.doubao.com"},
            {"title": "WPS AI", "desc": "è‡ªåŠ¨åŒ–åŠå…¬ä»»åŠ¡ï¼Œé™ä½è½¯ä»¶é‡‡è´­ä¸äººåŠ›æˆæœ¬", "source": "https://www.wps.cn/ai"}
        ],
        "efficiency": [
            {"title": "ç¾å›¾ç§€ç§€", "desc": "AI ä¸€é”®ä¿®å›¾ã€æŠ å›¾ã€ç¾åŒ–ï¼Œç§’å‡ºä¸“ä¸šæ•ˆæœ", "source": "https://xiuxiu.meitu.com"},
            {"title": "é€šä¹‰åƒé—® (Qwen)", "desc": "è‡ªåŠ¨ç”Ÿæˆå‘¨æŠ¥ã€é‚®ä»¶ã€æ€»ç»“ï¼Œæå‡å†™ä½œæ•ˆç‡", "source": "https://qwen.ai"},
            {"title": "Canva Magic Studio", "desc": "ç”¨æ–‡å­—ç”Ÿæˆæµ·æŠ¥ã€PPTã€ç¤¾äº¤åª’ä½“å›¾", "source": "https://www.canva.com/magic-studio/"},
            {"title": "Notion AI", "desc": "æ™ºèƒ½æ•´ç†ç¬”è®°ã€ç”Ÿæˆå¾…åŠã€æ€»ç»“é•¿æ–‡", "source": "https://www.notion.so/product/ai"}
        ]
    }

# ========================
# è¶‹åŠ¿æ–°é—»ï¼ˆ36æ°ªï¼‰
# ========================

def get_trend_news(max_items=3):
    try:
        res = requests.get("https://36kr.com/newsflashes", headers=HEADERS, timeout=10)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        items = []
        for item in soup.select('div.newsflash-item')[:max_items]:
            title_elem = item.select_one('a.article-title')
            if not title_elem:
                continue
            title = clean_text(title_elem.get_text(strip=True))
            link = "https://36kr.com" + title_elem['href'] if title_elem.has_attr('href') else "#"
            if any(kw in title for kw in ['AI', 'äººå·¥æ™ºèƒ½', 'å¤§æ¨¡å‹', 'AIGC', 'ç”Ÿæˆå¼']):
                items.append({"title": title, "desc": "æ¥æºï¼š36Kr", "source": link})
        return items or [{"title": "å…¨çƒ AI åº”ç”¨åŠ é€Ÿè½åœ°", "desc": "ä¼ä¸šéœ€æ±‚æ¿€å¢", "source": "https://36kr.com"}]
    except Exception as e:
        print(f"âš ï¸ è¶‹åŠ¿æ–°é—»æŠ“å–å¤±è´¥: {e}")
        return [{"title": "è¶‹åŠ¿åŠ è½½ä¸­...", "desc": "è¯·ç¨ååˆ·æ–°", "source": "#"}]

# ========================
# ä¸»ç¨‹åº
# ========================

def main():
    print("ğŸš€ å¼€å§‹æŠ“å–å…¨çƒ AI å·¥å…·...")

    all_tools = []

    print("ğŸ‡¨ğŸ‡³ æŠ“å– å‘ç°AI...")
    all_tools.extend(fetch_faxianai())

    print("ğŸŒ æŠ“å– FutureTools...")
    all_tools.extend(fetch_futuretools())

    # å»é‡
    all_tools = deduplicate(all_tools)

    # åˆ†ç±»
    cost_list = []
    efficiency_list = []
    for tool in all_tools:
        category = classify_tool(tool['desc'], tool['title'])
        if category == "cost":
            cost_list.append(tool)
        else:
            efficiency_list.append(tool)

    # é™åˆ¶æ•°é‡ï¼ˆé˜²æ­¢å‰ç«¯è¿‡è½½ï¼‰
    cost_list = cost_list[:5]
    efficiency_list = efficiency_list[:8]

    # å…œåº•
    manual = get_manual_tools()
    if len(cost_list) < 2:
        cost_list = manual["cost"]
    if len(efficiency_list) < 3:
        efficiency_list = manual["efficiency"]

    # è¶‹åŠ¿
    trend = get_trend_news()

    # æ„å»ºæœ€ç»ˆæ•°æ®
    data = {
        "cost": cost_list,
        "efficiency": efficiency_list,
        "trend": trend
    }

    # å®‰å…¨å†™å…¥ data.json
    try:
        with open('data.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… æˆåŠŸç”Ÿæˆ data.jsonï¼")
        print(f"   - æˆæœ¬æ€æ‰‹: {len(cost_list)} ä¸ª")
        print(f"   - æ•ˆç‡å€å¢: {len(efficiency_list)} ä¸ª")
        print(f"   - è¶‹åŠ¿é›·è¾¾: {len(trend)} æ¡")
    except Exception as e:
        print(f"âŒ å†™å…¥ data.json å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()