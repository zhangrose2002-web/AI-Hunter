# -*- coding: utf-8 -*-
"""
AI Hunter - ç¨³å®šç‰ˆçˆ¬è™«ï¼ˆæ··åˆè‡ªåŠ¨+æ‰‹åŠ¨ï¼‰
ç›®æ ‡ï¼šç¡®ä¿ç½‘ç«™å§‹ç»ˆå±•ç¤ºä¸°å¯Œå·¥å…·ï¼Œä¸ä¾èµ–ä¸å¯é çš„åŠ¨æ€ç½‘ç«™
"""

import json
import requests
import os
import datetime
from bs4 import BeautifulSoup

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36"
}

def clean_text(text):
    if not text:
        return ""
    return ' '.join(str(text).split())

def fetch_ai_bot():
    """æŠ“å– https://ai-bot.cn/ â€”â€” å¯é çš„ä¸­æ–‡æº"""
    print("ğŸ‡¨ğŸ‡³ æŠ“å– ai-bot.cn...")
    tools = []
    try:
        res = requests.get("https://ai-bot.cn/", headers=HEADERS, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        cards = soup.select('.url-card')[:20]
        for card in cards:
            title_elem = card.select_one('strong')
            desc_elem = card.select_one('.url-info p')
            link_elem = card.select_one('a')
            if title_elem and link_elem:
                title = clean_text(title_elem.get_text())
                desc = clean_text(desc_elem.get_text()) if desc_elem else "AI å·¥å…·"
                link = link_elem['href']
                if title and len(title) > 1:
                    tools.append({"title": title, "desc": desc, "source": link})
        print(f"âœ… æŠ“å–åˆ° {len(tools)} ä¸ªä¸­æ–‡å·¥å…·")
    except Exception as e:
        print(f"âš ï¸ ai-bot.cn æŠ“å–å¤±è´¥: {e}")
    return tools

def get_manual_global_tools():
    """æ‰‹åŠ¨ç»´æŠ¤çš„å›½å¤–çƒ­é—¨ AI å·¥å…·ï¼ˆç¡®ä¿æ˜¾ç¤ºï¼‰"""
    return [
        {"title": "Gamma.app", "desc": "ç”¨ä¸€å¥è¯ç”Ÿæˆ PPTã€æ–‡æ¡£æˆ–ç½‘é¡µï¼Œæ— éœ€è®¾è®¡", "source": "https://gamma.app"},
        {"title": "Runway ML", "desc": "AI è§†é¢‘ç¼–è¾‘ï¼šæ–‡æœ¬ç”Ÿæˆè§†é¢‘ã€ç»¿å¹•æŠ åƒã€è¿åŠ¨è¿½è¸ª", "source": "https://runwayml.com"},
        {"title": "HeyGen", "desc": "åˆ›å»º AI æ•°å­—äººè§†é¢‘ï¼Œæ”¯æŒå¤šè¯­è¨€å£å‹åŒæ­¥", "source": "https://www.heygen.com"},
        {"title": "ElevenLabs", "desc": "è¶…æ‹ŸçœŸ AI è¯­éŸ³åˆæˆï¼Œæ”¯æŒæƒ…æ„Ÿä¸å¤šè¯­ç§", "source": "https://elevenlabs.io"},
        {"title": "Notion AI", "desc": "æ™ºèƒ½ç¬”è®°åŠ©æ‰‹ï¼šæ€»ç»“ã€æ‰©å†™ã€ç¿»è¯‘ã€ç”Ÿæˆå¾…åŠ", "source": "https://www.notion.so/product/ai"},
        {"title": "Otter.ai", "desc": "å®æ—¶è¯­éŸ³è½¬æ–‡å­—ï¼Œè‡ªåŠ¨ç”Ÿæˆä¼šè®®æ‘˜è¦", "source": "https://otter.ai"},
        {"title": "Canva Magic Studio", "desc": "AI è®¾è®¡å¥—ä»¶ï¼šæ–‡ç”Ÿå›¾ã€èƒŒæ™¯ç§»é™¤ã€æ–‡æ¡ˆç”Ÿæˆ", "source": "https://www.canva.com/magic-studio/"},
        {"title": "Perplexity AI", "desc": "ä¼šè”ç½‘çš„ç­”æ¡ˆå¼•æ“ï¼Œæ›¿ä»£ä¼ ç»Ÿæœç´¢", "source": "https://www.perplexity.ai"},
        {"title": "Loom AI", "desc": "å½•åˆ¶è§†é¢‘æ—¶è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦ã€ç« èŠ‚å’Œè¡ŒåŠ¨é¡¹", "source": "https://www.loom.com"},
        {"title": "Fireflies.ai", "desc": "è‡ªåŠ¨è®°å½•å¹¶åˆ†æ Zoom/Teams ä¼šè®®å†…å®¹", "source": "https://fireflies.ai"}
    ]

def get_manual_cost_tools():
    """é™æœ¬ç±»å·¥å…·ï¼ˆåä¼ä¸š/å®¢æœ/è‡ªåŠ¨åŒ–ï¼‰"""
    return [
        {"title": "Doubao (è±†åŒ…)", "desc": "å…è´¹å¤šæ¨¡æ€ AI åŠ©æ‰‹ï¼Œé€‚åˆå®¢æœé—®ç­”", "source": "https://www.doubao.com"},
        {"title": "WPS AI", "desc": "è‡ªåŠ¨åŒ–åŠå…¬æµç¨‹ï¼Œå‡å°‘äººåŠ›é‡å¤æ“ä½œ", "source": "https://www.wps.cn/ai"},
        {"title": "Tidbyt", "desc": "å¼€æºç¡¬ä»¶çœ‹æ¿ï¼Œæ›¿ä»£æ˜‚è´µ SaaS ç›‘æ§å·¥å…·", "source": "https://tidbyt.com"},
        {"title": "Zapier", "desc": "è¿æ¥ä¸åŒ App è‡ªåŠ¨åŒ–å·¥ä½œæµï¼ŒèŠ‚çœå¼€å‘æˆæœ¬", "source": "https://zapier.com"}
    ]

def get_trend_news():
    """æŠ“å– 36Kr å¿«è®¯ï¼ˆå¸¦ AI å…³é”®è¯è¿‡æ»¤ï¼‰"""
    try:
        res = requests.get("https://36kr.com/newsflashes", headers=HEADERS, timeout=10)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        items = []
        for item in soup.select('div.newsflash-item')[:5]:
            title_elem = item.select_one('a.article-title')
            if not title_elem:
                continue
            title = clean_text(title_elem.get_text())
            if any(kw in title for kw in ['AI', 'äººå·¥æ™ºèƒ½', 'å¤§æ¨¡å‹', 'AIGC', 'ç”Ÿæˆå¼']):
                link = "https://36kr.com" + title_elem['href'] if title_elem.has_attr('href') else "#"
                items.append({"title": "ğŸ”¥ " + title, "desc": "æ¥æºï¼š36Kr", "source": link})
        return items[:3] or [{"title": "å…¨çƒ AI åº”ç”¨åŠ é€Ÿè½åœ°", "desc": "ä¼ä¸šéœ€æ±‚æ¿€å¢", "source": "https://36kr.com"}]
    except Exception as e:
        print(f"âš ï¸ è¶‹åŠ¿æ–°é—»æŠ“å–å¤±è´¥: {e}")
        return [{"title": "è¶‹åŠ¿åŠ è½½ä¸­...", "desc": "è¯·ç¨ååˆ·æ–°", "source": "#"}]

def deduplicate(tools):
    seen = set()
    unique = []
    for t in tools:
        key = t['title'].strip().lower()
        if key and key not in seen:
            seen.add(key)
            unique.append(t)
    return unique

def main():
    print("ğŸš€ AI Hunter ç¨³å®šç‰ˆå¯åŠ¨...")

    # 1. æŠ“å–å›½å†…å·¥å…·
    auto_tools = fetch_ai_bot()

    # 2. æ‰‹åŠ¨æ·»åŠ å›½å¤–å·¥å…·ï¼ˆç¡®ä¿æ•°é‡ï¼‰
    manual_efficiency = get_manual_global_tools()
    manual_cost = get_manual_cost_tools()

    # 3. åˆå¹¶å¹¶å»é‡
    all_efficiency = deduplicate(auto_tools + manual_efficiency)
    all_cost = deduplicate(manual_cost)

    # 4. æ·»åŠ åŒæ­¥éªŒè¯æ ‡è®°ï¼ˆç”¨äºç¡®è®¤ Action æ˜¯å¦ç”Ÿæ•ˆï¼‰
    now_str = datetime.datetime.now(datetime.timezone.utc).strftime("%m-%d %H:%M UTC")
    all_efficiency.insert(0, {
        "title": f"âœ… æ•°æ®å·²æ›´æ–° [{now_str}]",
        "desc": "GitHub Actions è‡ªåŠ¨åŒæ­¥æˆåŠŸ",
        "source": "#"
    })

    # 5. è·å–è¶‹åŠ¿
    trend = get_trend_news()

    # 6. æ„å»ºæœ€ç»ˆæ•°æ®
    data = {
        "cost": all_cost,
        "efficiency": all_efficiency,
        "trend": trend
    }

    # 7. å†™å…¥æ–‡ä»¶
    try:
        with open('data.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ… æˆåŠŸå†™å…¥ data.json")
        print(f"   - é™æœ¬å·¥å…·: {len(all_cost)} ä¸ª")
        print(f"   - æ•ˆç‡å·¥å…·: {len(all_efficiency)} ä¸ª")
        print(f"   - è¶‹åŠ¿æ–°é—»: {len(trend)} æ¡")
        print(f"   - æ–‡ä»¶å¤§å°: {os.path.getsize('data.json')} å­—èŠ‚")
    except Exception as e:
        print(f"âŒ å†™å…¥å¤±è´¥: {e}")
        exit(1)

if __name__ == "__main__":
    main()
